{"name":"Implementation Of Deduplication Algorithm","tagline":"Everything can be improved. ~Clarence W. Barron","body":"###What Deduplication Is\r\nAccording to wikipedia, \"Data deduplication is a specific form of compression where redundant data is eliminated, typically to improve storage utilization. In the deduplication process, duplicate data is deleted, leaving only one copy of the data to be stored. However, indexing of all data is still retained should that data ever be required. Deduplication is able to reduce the required storage capacity since only the unique data is stored. \r\n\r\n### Methods For DedupLication Algorithm\r\n1. file-level Deduplication\r\n2. Block-level Deduplication\r\n\r\n**file-level deduplication** watches for multiple copies of the same file, stores the first copy, and then just links the other references to the first file. Only one copy gets stored on the disk/tape archive. Ultimately, the space you save on disk relates to how many copies of the file there were in the file system.\r\n\r\nlets assume a company having a 1000 employee share a common file say \"data.txt\" which is 10MB in Size.Each employee do the same changes and save the exact similar 1000 copies of file on server.so estimated storage require to save a file on server side is 10 GB.\r\n\r\n![](https://cloud.githubusercontent.com/assets/13395805/9021561/ab1729ee-3865-11e5-824d-1fdc4b5756b6.png)\r\n\r\nHere the point is if All the files are identical then why to upload all the files on server.just save a single copy on server and put a pointers in a users folder that points to a single copy on server.So thats how Data Deduplication technique used to save the TB's of storage.\r\n\r\n**Block-level Deduplication**, sometimes called variable block-level deduplication, looks at the data block itself to see if another copy of this block already exists. If so, the second (and subsequent) copies are not stored on the disk/tape, but a link/pointer is created to point to the original copy.\r\n\r\n![](https://cloud.githubusercontent.com/assets/13395805/9022930/41e1a472-38a6-11e5-8535-a34e095b5be9.PNG)\r\n\r\nlets say we have three users each having 4 data blocks.Green and Gray blocks are common in three users so they backed up in data center.Blue,red and purple block are common between two users hence they backed up in Data center.\r\nHere the Important point is the memory required for block data in data storage is very less which is equal to sizeof(block) in memory.\r\n\r\nBlock level deduplication is always efficient then file-level deduplication because In file level you have to dump whole file in data storage if its version changed where as in block level you have to dump the changed block which takes comparatively less space in data storage.\r\n\r\n### Implemention Of DedupLication Algorithm \r\n\r\n### Creating pages manually\r\nIf you prefer to not use the automatic generator, push a branch named `gh-pages` to your repository to create a page manually. In addition to supporting regular HTML content, GitHub Pages support Jekyll, a simple, blog aware static site generator. Jekyll makes it easy to create site-wide headers and footers without having to copy them across every page. It also offers intelligent blog support and other advanced templating features.\r\n\r\n### Authors and Contributors\r\nYou can @mention a GitHub username to generate a link to their profile. The resulting `<a>` element will link to the contributor's GitHub Profile. For example: In 2007, Chris Wanstrath (@defunkt), PJ Hyett (@pjhyett), and Tom Preston-Werner (@mojombo) founded GitHub.\r\n\r\n### Support or Contact\r\nHaving trouble with Pages? Check out our [documentation](https://help.github.com/pages) or [contact support](https://github.com/contact) and weâ€™ll help you sort it out.","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}